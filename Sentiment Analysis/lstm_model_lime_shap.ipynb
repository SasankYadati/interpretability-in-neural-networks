{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build a LSTM model to perform sentiment analysis on IMDB dataset.\n",
    "Compute\n",
    "    -Performance\n",
    "    -Stability of LIME explanations\n",
    "    -Stability of SHAP explanations\n",
    "'''\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TOXIC AREA!\n",
    "GLOBAL VARIABLES AHEAD\n",
    "'''\n",
    "# hyperparameters\n",
    "VOCAB_SIZE = 10000\n",
    "PAD_VALUE = 0\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "MAX_SEQ_LEN = 150\n",
    "WORD_VEC_DIMS = 50\n",
    "LSTM_UNITS = 64\n",
    "\n",
    "# initialize word_index and reverse_word_index\n",
    "word_index = {}\n",
    "reverse_word_index = {}\n",
    "# build word_index and reverse_word_index\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "# first few indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = PAD_VALUE\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "input_seq = tf.placeholder(tf.int32, [None, MAX_SEQ_LEN], name='input_seq')\n",
    "target_class = tf.placeholder(tf.float32, [None, 1], name='target_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    imdb = keras.datasets.imdb\n",
    "\n",
    "    (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=VOCAB_SIZE)\n",
    "\n",
    "    train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "    test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "    valid_data = train_data[0:5000]\n",
    "    valid_labels = train_labels[0:5000]\n",
    "\n",
    "    train_data = train_data[5000:]\n",
    "    train_labels = train_labels[5000:]\n",
    "\n",
    "    return imdb, train_data, train_labels, valid_data, valid_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def decodeExampleText(text, word_index, reverse_word_index):\n",
    "    '''\n",
    "    for given text, returns decoded form.\n",
    "    numbers=>words\n",
    "    '''\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessData(train_data, valid_data, test_data):\n",
    "    '''\n",
    "    pad the arrays so they all have the same length,\n",
    "    then create an integer tensor of shape max_length * num_reviews.\n",
    "    we can use an embedding layer capable of handling this shape as the first layer in our network.\n",
    "    '''\n",
    "\n",
    "    train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=PAD_VALUE, padding='post', maxlen=MAX_SEQ_LEN)\n",
    "    valid_data = keras.preprocessing.sequence.pad_sequences(valid_data, value=PAD_VALUE, padding='post', maxlen=MAX_SEQ_LEN)\n",
    "    test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=PAD_VALUE, padding='post', maxlen=MAX_SEQ_LEN)\n",
    "    \n",
    "    train_data = np.reshape(train_data, (train_data.shape[0], MAX_SEQ_LEN))\n",
    "    valid_data = np.reshape(valid_data, (valid_data.shape[0], MAX_SEQ_LEN))\n",
    "    test_data = np.reshape(test_data, (test_data.shape[0], MAX_SEQ_LEN))\n",
    "\n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    '''\n",
    "    returns output, cost and optimizer as tensor ops.\n",
    "    '''\n",
    "    # embedding layer\n",
    "    word_vec = tf.Variable(tf.truncated_normal([VOCAB_SIZE, WORD_VEC_DIMS]), dtype=tf.float32, name='Word-Vectors')\n",
    "    input_vec = tf.nn.embedding_lookup(word_vec, input_seq)\n",
    "\n",
    "    # rnn lstm layer\n",
    "    rnn_cell = tf.nn.rnn_cell.LSTMCell(LSTM_UNITS)\n",
    "    rnn_cell = tf.contrib.rnn.DropoutWrapper(cell=rnn_cell, output_keep_prob=0.5)\n",
    "\n",
    "    # finally, the rnn put together\n",
    "    output, _ = tf.nn.dynamic_rnn(rnn_cell, input_vec, dtype=tf.float32)\n",
    "    \n",
    "    output = tf.layers.flatten(output)\n",
    "\n",
    "    output = tf.layers.dense(output, 32)\n",
    "    output = tf.nn.relu(output)\n",
    "\n",
    "    output = tf.layers.dense(output, 1)\n",
    "    output = tf.nn.sigmoid(output)\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(target_class, output)\n",
    "   \n",
    "    optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "    # a list of metrics to measure accuracy, precision, recall, f1-score\n",
    "    metrics = []\n",
    "\n",
    "    round_output = tf.round(output)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(target_class, round_output, name='Accuracy')\n",
    "   \n",
    "    precision = tf.metrics.precision(target_class, round_output, name='Precision')\n",
    "  \n",
    "    recall = tf.metrics.recall(target_class, round_output, name='Recall')\n",
    "    \n",
    "    metrics.append(accuracy)\n",
    "    metrics.append(precision)\n",
    "    metrics.append(recall)\n",
    "\n",
    "    return optimizer, loss, output, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training: Acc - 0.5943 | Prec - 0.7146 | Rec - 0.3079\n",
      "Validation: Acc - 0.6216 | Prec - 0.7970 | Rec - 0.3216\n",
      "Epoch 1\n",
      "Training: Acc - 0.6615 | Prec - 0.8125 | Rec - 0.4174\n",
      "Validation: Acc - 0.6987 | Prec - 0.8376 | Rec - 0.4907\n",
      "Epoch 2\n",
      "Training: Acc - 0.7244 | Prec - 0.8478 | Rec - 0.5453\n",
      "Validation: Acc - 0.7443 | Prec - 0.8591 | Rec - 0.5828\n",
      "Epoch 3\n",
      "Training: Acc - 0.7607 | Prec - 0.8666 | Rec - 0.6148\n",
      "Validation: Acc - 0.7693 | Prec - 0.8770 | Rec - 0.6252\n",
      "Epoch 4\n",
      "Training: Acc - 0.7806 | Prec - 0.8833 | Rec - 0.6456\n",
      "Validation: Acc - 0.7822 | Prec - 0.8900 | Rec - 0.6428\n",
      "Epoch 5\n",
      "Training: Acc - 0.7906 | Prec - 0.8952 | Rec - 0.6571\n",
      "Validation: Acc - 0.7993 | Prec - 0.9005 | Rec - 0.6717\n",
      "Epoch 6\n",
      "Training: Acc - 0.8069 | Prec - 0.9033 | Rec - 0.6864\n",
      "Validation: Acc - 0.8141 | Prec - 0.9064 | Rec - 0.6996\n",
      "Epoch 7\n",
      "Training: Acc - 0.8200 | Prec - 0.9078 | Rec - 0.7115\n",
      "Validation: Acc - 0.8243 | Prec - 0.9113 | Rec - 0.7177\n",
      "Epoch 8\n",
      "Training: Acc - 0.8290 | Prec - 0.9133 | Rec - 0.7261\n",
      "Validation: Acc - 0.8309 | Prec - 0.9161 | Rec - 0.7276\n",
      "Epoch 9\n",
      "Training: Acc - 0.8345 | Prec - 0.9180 | Rec - 0.7340\n",
      "Validation: Acc - 0.8389 | Prec - 0.9197 | Rec - 0.7418\n",
      "Epoch 10\n",
      "Training: Acc - 0.8426 | Prec - 0.9204 | Rec - 0.7493\n",
      "Validation: Acc - 0.8459 | Prec - 0.9226 | Rec - 0.7545\n",
      "Epoch 11\n",
      "Training: Acc - 0.8490 | Prec - 0.9239 | Rec - 0.7600\n",
      "Validation: Acc - 0.8522 | Prec - 0.9243 | Rec - 0.7666\n",
      "Epoch 12\n",
      "Training: Acc - 0.8551 | Prec - 0.9246 | Rec - 0.7726\n",
      "Validation: Acc - 0.8582 | Prec - 0.9261 | Rec - 0.7778\n",
      "Epoch 13\n",
      "Training: Acc - 0.8608 | Prec - 0.9268 | Rec - 0.7828\n",
      "Validation: Acc - 0.8634 | Prec - 0.9276 | Rec - 0.7878\n",
      "Epoch 14\n",
      "Training: Acc - 0.8657 | Prec - 0.9278 | Rec - 0.7925\n",
      "Validation: Acc - 0.8682 | Prec - 0.9292 | Rec - 0.7964\n",
      "Epoch 15\n",
      "Training: Acc - 0.8701 | Prec - 0.9298 | Rec - 0.8001\n",
      "Validation: Acc - 0.8722 | Prec - 0.9304 | Rec - 0.8041\n",
      "Epoch 16\n",
      "Training: Acc - 0.8740 | Prec - 0.9305 | Rec - 0.8077\n",
      "Validation: Acc - 0.8760 | Prec - 0.9314 | Rec - 0.8112\n",
      "Epoch 17\n",
      "Training: Acc - 0.8777 | Prec - 0.9317 | Rec - 0.8145\n",
      "Validation: Acc - 0.8795 | Prec - 0.9323 | Rec - 0.8178\n",
      "Epoch 18\n",
      "Training: Acc - 0.8810 | Prec - 0.9325 | Rec - 0.8208\n",
      "Validation: Acc - 0.8827 | Prec - 0.9336 | Rec - 0.8236\n",
      "Epoch 19\n",
      "Training: Acc - 0.8841 | Prec - 0.9341 | Rec - 0.8260\n",
      "Validation: Acc - 0.8857 | Prec - 0.9349 | Rec - 0.8286\n",
      "Epoch 20\n",
      "Training: Acc - 0.8870 | Prec - 0.9353 | Rec - 0.8311\n",
      "Validation: Acc - 0.8885 | Prec - 0.9362 | Rec - 0.8332\n",
      "Epoch 21\n",
      "Training: Acc - 0.8897 | Prec - 0.9367 | Rec - 0.8353\n",
      "Validation: Acc - 0.8911 | Prec - 0.9376 | Rec - 0.8375\n",
      "Epoch 22\n",
      "Training: Acc - 0.8922 | Prec - 0.9379 | Rec - 0.8396\n",
      "Validation: Acc - 0.8934 | Prec - 0.9388 | Rec - 0.8412\n",
      "Epoch 23\n",
      "Training: Acc - 0.8944 | Prec - 0.9392 | Rec - 0.8428\n",
      "Validation: Acc - 0.8956 | Prec - 0.9400 | Rec - 0.8448\n",
      "Epoch 24\n",
      "Training: Acc - 0.8965 | Prec - 0.9402 | Rec - 0.8465\n",
      "Validation: Acc - 0.8976 | Prec - 0.9409 | Rec - 0.8481\n",
      "Epoch 25\n",
      "Training: Acc - 0.8984 | Prec - 0.9412 | Rec - 0.8495\n",
      "Validation: Acc - 0.8995 | Prec - 0.9417 | Rec - 0.8512\n",
      "Epoch 26\n",
      "Training: Acc - 0.9003 | Prec - 0.9419 | Rec - 0.8527\n",
      "Validation: Acc - 0.9013 | Prec - 0.9426 | Rec - 0.8542\n",
      "Epoch 27\n",
      "Training: Acc - 0.9020 | Prec - 0.9429 | Rec - 0.8554\n",
      "Validation: Acc - 0.9030 | Prec - 0.9435 | Rec - 0.8569\n",
      "Epoch 28\n",
      "Training: Acc - 0.9037 | Prec - 0.9437 | Rec - 0.8582\n",
      "Validation: Acc - 0.9046 | Prec - 0.9442 | Rec - 0.8597\n",
      "Epoch 29\n",
      "Training: Acc - 0.9053 | Prec - 0.9444 | Rec - 0.8609\n",
      "Validation: Acc - 0.9062 | Prec - 0.9450 | Rec - 0.8621\n",
      "Epoch 30\n",
      "Training: Acc - 0.9067 | Prec - 0.9452 | Rec - 0.8631\n",
      "Validation: Acc - 0.9076 | Prec - 0.9457 | Rec - 0.8644\n",
      "Epoch 31\n",
      "Training: Acc - 0.9082 | Prec - 0.9457 | Rec - 0.8656\n",
      "Validation: Acc - 0.9090 | Prec - 0.9462 | Rec - 0.8669\n",
      "Epoch 32\n",
      "Training: Acc - 0.9096 | Prec - 0.9463 | Rec - 0.8680\n",
      "Validation: Acc - 0.9103 | Prec - 0.9468 | Rec - 0.8691\n",
      "Epoch 33\n",
      "Training: Acc - 0.9109 | Prec - 0.9470 | Rec - 0.8700\n",
      "Validation: Acc - 0.9116 | Prec - 0.9475 | Rec - 0.8712\n",
      "Epoch 34\n",
      "Training: Acc - 0.9122 | Prec - 0.9477 | Rec - 0.8721\n",
      "Validation: Acc - 0.9129 | Prec - 0.9481 | Rec - 0.8732\n",
      "Epoch 35\n",
      "Training: Acc - 0.9134 | Prec - 0.9483 | Rec - 0.8740\n",
      "Validation: Acc - 0.9140 | Prec - 0.9487 | Rec - 0.8750\n",
      "Epoch 36\n",
      "Training: Acc - 0.9145 | Prec - 0.9489 | Rec - 0.8758\n",
      "Validation: Acc - 0.9151 | Prec - 0.9493 | Rec - 0.8766\n",
      "Epoch 37\n",
      "Training: Acc - 0.9155 | Prec - 0.9495 | Rec - 0.8772\n",
      "Validation: Acc - 0.9161 | Prec - 0.9499 | Rec - 0.8782\n",
      "Epoch 38\n",
      "Training: Acc - 0.9165 | Prec - 0.9500 | Rec - 0.8790\n",
      "Validation: Acc - 0.9171 | Prec - 0.9504 | Rec - 0.8798\n",
      "Epoch 39\n",
      "Training: Acc - 0.9175 | Prec - 0.9506 | Rec - 0.8804\n",
      "Validation: Acc - 0.9181 | Prec - 0.9510 | Rec - 0.8813\n",
      "Epoch 40\n",
      "Training: Acc - 0.9185 | Prec - 0.9510 | Rec - 0.8820\n",
      "Validation: Acc - 0.9190 | Prec - 0.9513 | Rec - 0.8829\n",
      "Epoch 41\n",
      "Training: Acc - 0.9194 | Prec - 0.9513 | Rec - 0.8836\n",
      "Validation: Acc - 0.9199 | Prec - 0.9516 | Rec - 0.8845\n",
      "Epoch 42\n",
      "Training: Acc - 0.9203 | Prec - 0.9517 | Rec - 0.8851\n",
      "Validation: Acc - 0.9208 | Prec - 0.9520 | Rec - 0.8859\n",
      "Epoch 43\n",
      "Training: Acc - 0.9211 | Prec - 0.9521 | Rec - 0.8864\n",
      "Validation: Acc - 0.9216 | Prec - 0.9524 | Rec - 0.8872\n",
      "Epoch 44\n",
      "Training: Acc - 0.9219 | Prec - 0.9525 | Rec - 0.8878\n",
      "Validation: Acc - 0.9224 | Prec - 0.9528 | Rec - 0.8885\n",
      "Epoch 45\n",
      "Training: Acc - 0.9227 | Prec - 0.9529 | Rec - 0.8890\n",
      "Validation: Acc - 0.9232 | Prec - 0.9532 | Rec - 0.8897\n",
      "Epoch 46\n",
      "Training: Acc - 0.9234 | Prec - 0.9532 | Rec - 0.8903\n",
      "Validation: Acc - 0.9239 | Prec - 0.9534 | Rec - 0.8910\n",
      "Epoch 47\n",
      "Training: Acc - 0.9241 | Prec - 0.9534 | Rec - 0.8915\n",
      "Validation: Acc - 0.9246 | Prec - 0.9537 | Rec - 0.8922\n",
      "Epoch 48\n",
      "Training: Acc - 0.9249 | Prec - 0.9538 | Rec - 0.8927\n",
      "Validation: Acc - 0.9253 | Prec - 0.9541 | Rec - 0.8933\n",
      "Epoch 49\n",
      "Training: Acc - 0.9256 | Prec - 0.9541 | Rec - 0.8938\n",
      "Validation: Acc - 0.9260 | Prec - 0.9544 | Rec - 0.8943\n"
     ]
    }
   ],
   "source": [
    "imdb, train_x, train_y, valid_x, valid_y, test_x, test_y = loadData()\n",
    "train_x, valid_x, test_x = preprocessData(train_x, valid_x, test_x)\n",
    "\n",
    "optimizer, loss, output, metrics = buildModel()\n",
    "\n",
    "num_batches = train_x.shape[0] // BATCH_SIZE\n",
    "\n",
    "initializer_g = tf.global_variables_initializer()\n",
    "initializer_l = tf.local_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run([initializer_g, initializer_l])\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "\n",
    "    for batch in range(0, num_batches):\n",
    "        l = batch*BATCH_SIZE\n",
    "        r = min((batch+1)*BATCH_SIZE, train_x.shape[0]-1)\n",
    "\n",
    "        batch_x = train_x[l:r]\n",
    "        batch_y = train_y[l:r]\n",
    "\n",
    "        _, _, _, _ = sess.run([optimizer] + metrics, {input_seq: batch_x, target_class: batch_y})\n",
    "\n",
    "    # log summaries every epoch\n",
    "    acc_train, prec_train, rec_train = sess.run(metrics, {input_seq: train_x, target_class: train_y})\n",
    "    acc_valid, prec_valid, rec_valid = sess.run(metrics, {input_seq: valid_x, target_class: valid_y})\n",
    "\n",
    "    # print metrics\n",
    "    print(\"Training: Acc - {0:.4f} | Prec - {1:.4f} | Rec - {2:.4f}\".format(acc_train[0], prec_train[0], rec_train[0]))\n",
    "    print(\"Validation: Acc - {0:.4f} | Prec - {1:.4f} | Rec - {2:.4f}\".format(acc_valid[0], prec_valid[0], rec_valid[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Todo: \n",
    "# Calculate Performance metrics on test set (done)\n",
    "# LIME explanations (done)\n",
    "# Stability of LIME explanations on test set (done)\n",
    "# Shap explanations (done)\n",
    "# Stability of Shap explanations on test set (done)\n",
    "# Images of LIME & Shap explanations for few random examples from test set (done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance: Accuracy - 0.9258085489273071 | Precision - 0.9542996883392334 | Recall - 0.894135594367981 | F1-score - 0.9232385109947449\n"
     ]
    }
   ],
   "source": [
    "# Calculate Performance metrics on test set\n",
    "acc_test, prec_test, rec_test = sess.run(metrics, {input_seq: test_x, target_class: test_y})\n",
    "\n",
    "acc_test = acc_test[0]\n",
    "prec_test = prec_test[0]\n",
    "rec_test = rec_test[0]\n",
    "f1_score = 2.0*prec_test*rec_test/(prec_test+rec_test)\n",
    "\n",
    "print(\"Test Performance: Accuracy - {} | Precision - {} | Recall - {} | F1-score - {}\".format(acc_test, prec_test, rec_test, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer, IndexedString, TextDomainMapper\n",
    "\n",
    "class_names = ['negative','positive']\n",
    "explainer = LimeTextExplainer(class_names=class_names, split_expression=r'\\s+', bow=True)\n",
    "\n",
    "def makePrediction(strings):\n",
    "    '''\n",
    "    takes a list of d strings \n",
    "    and outputs a (d, k) numpy array with prediction probabilities, \n",
    "    where k is the numb/er of classes\n",
    "    '''\n",
    "    # convert d strings into shape (d,MAX_SEQ_LEN)\n",
    "    global word_index\n",
    "    for j in range(0,len(strings)):\n",
    "        strings[j] = strings[j].split(' ')\n",
    "        for i in range(0,len(strings[j])):\n",
    "            if strings[j][i] in word_index.keys() and word_index[strings[j][i]] < VOCAB_SIZE:\n",
    "                strings[j][i] = word_index[strings[j][i]]\n",
    "            else:\n",
    "                strings[j][i] = word_index[\"<UNK>\"]\n",
    "    strings = np.array(strings)\n",
    "    \n",
    "    # calculate the output on strings\n",
    "    pred = sess.run(output, {input_seq: strings})\n",
    "    \n",
    "    # reshape it into (d,NUM_CLASSES) corresponding to d output probability distributions\n",
    "    pred = pred.tolist()\n",
    "    for i in range(0, len(pred)):\n",
    "        pred[i].insert(0,1-pred[i][0])\n",
    "    \n",
    "    return np.array(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stability of explanations is calculated as follows: Stability is the ratio of change in explanation to change in input. Each explanation is a vector of values. \n",
    "Change in explanation is calculated as the magnitude of the vector obtained by taking the difference between the two explanations.\n",
    "Change in input is simply (noise/MAX_SEQ_LEN) ** 0.5\n",
    "We hope this formalization scales to LIME, SHAP and SENN well enough to be able to compare their values fairly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Stability on test set\n",
    "# Stability = Change in explanations / Change in input\n",
    "# Average stability over the test set seems a good estimation\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "def noisifyExample(example, num_samples=100, noise=5):\n",
    "    '''\n",
    "    for a given example text or array of word ids,\n",
    "    return a list of texts of size num_samples,\n",
    "    where each text is same as example except noise amount of words are removed randomly.\n",
    "    '''\n",
    "    noisy_examples = []\n",
    "    \n",
    "    if type(example) is not str: # given an array of word ids, convert it into text\n",
    "        example = [reverse_word_index[word_id] for word_id in example]\n",
    "        example = \" \".join(example)\n",
    "    \n",
    "    while len(noisy_examples) < num_samples:\n",
    "        indices_to_remove = set()\n",
    "        while len(indices_to_remove) < noise:\n",
    "            indices_to_remove.add(random.randint(0,MAX_SEQ_LEN-1))\n",
    "        new_exmp = example.split(\" \")\n",
    "        for ind in indices_to_remove:\n",
    "            new_exmp[ind] = \"<PAD>\"\n",
    "        new_exmp = \" \".join(new_exmp)\n",
    "        noisy_examples.append(new_exmp)        \n",
    "    return noisy_examples\n",
    "\n",
    "def vectorDifference(vec1, vec2):\n",
    "    '''\n",
    "    return magnitude of the vector gained by subtracting vec2 from vec1.\n",
    "    '''\n",
    "    assert len(vec1) == len(vec2)\n",
    "    n = len(vec1)\n",
    "    \n",
    "    # compute magnitude of difference between vectors\n",
    "    vec_diff = [vec1[ind]-vec2[ind] for ind in range(n)] # difference\n",
    "    vec_diff = [x**2 for x in vec_diff] # squared\n",
    "    vec_diff = sum(vec_diff)\n",
    "    vec_diff = vec_diff ** 0.5\n",
    "    \n",
    "    return vec_diff\n",
    "    \n",
    "\n",
    "def calculateStabilityLime(example, num_samples, noises):\n",
    "    '''\n",
    "    example: original text\n",
    "    num_samples: size of neighborhood around 'example'\n",
    "    noises: list of integers, each indicating the amount of noise\n",
    "    \n",
    "    returns: average stability, which is a dictionary.\n",
    "             maps noise to avg stability of 'example'.\n",
    "    \n",
    "    stability = vectorDifference(exp1,exp2) / normalised_noise ** 0.5\n",
    "    \n",
    "    change in input = normalised_noise ** 0.5\n",
    "    change in explanation = calculated using vectorDifference()\n",
    "    '''\n",
    "    assert num_samples > 0\n",
    "    \n",
    "    # get noisy_examples for example\n",
    "    noisy_examples = {}\n",
    "    for noise in noises:\n",
    "        noisy_examples[str(noise)] = noisifyExample(example, num_samples, noise)\n",
    "            \n",
    "    \n",
    "    # get explanation for example\n",
    "    exp = explainer.explain_instance(example, makePrediction, num_features=5, num_samples=2000)\n",
    "    exp = exp.as_list()\n",
    "    \n",
    "    \n",
    "    # get words from explanation\n",
    "    words = [e[0] for e in exp]\n",
    "    words = set(words)\n",
    "    \n",
    "    # get explanations for noisy_examples\n",
    "    noisy_explanations = {}\n",
    "    for noise in noises:\n",
    "        noisy_explanations[str(noise)] = []\n",
    "    \n",
    "    # calculate stability for each noisy explanation w.r.t explanation\n",
    "    stabilities = {}\n",
    "    \n",
    "    \n",
    "    for noise in noises:\n",
    "        stabilities[str(noise)] = 0\n",
    "        for noisy_example in noisy_examples[str(noise)]:\n",
    "            exp_ = exp[:]\n",
    "            noisy_exp = explainer.explain_instance(noisy_example, makePrediction, num_features=5, num_samples=2000)\n",
    "            # fig = noisy_exp.as_pyplot_figure()\n",
    "            noisy_exp = noisy_exp.as_list()\n",
    "            noisy_words = [e[0] for e in noisy_exp]\n",
    "            noisy_words = set(noisy_words)\n",
    "\n",
    "            # make exp_ and noisy_exp have the same words\n",
    "            total_words = words| noisy_words\n",
    "            \n",
    "            for word in total_words:\n",
    "                if word not in noisy_words:\n",
    "                    noisy_exp.append((word,0))\n",
    "                if word not in words:\n",
    "                    exp_.append((word,0))\n",
    "        \n",
    "            # sort both explanations by words\n",
    "            exp_.sort(key = lambda x:x[0])\n",
    "            noisy_exp.sort(key = lambda x:x[0])\n",
    "            \n",
    "            \n",
    "            exp_ = list(map(lambda x: x[1], exp_))\n",
    "            noisy_exp = list(map(lambda x: x[1], noisy_exp))\n",
    "    \n",
    "            # compute vector difference\n",
    "            vec_diff = vectorDifference(exp_, noisy_exp)\n",
    "\n",
    "            # compute stability\n",
    "            stability = vec_diff / (noise/MAX_SEQ_LEN)**0.5\n",
    "            \n",
    "            # store the value\n",
    "            stabilities[str(noise)] += stability\n",
    "        stabilities[str(noise)] /= num_samples\n",
    "    \n",
    "    return stabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Stability of LIME explanations on test set\n",
    "# NOTE: these computations are expensive so test set will be reduced to 1000 examples\n",
    "\n",
    "# range of noises\n",
    "noises = [x for x in range(3,21,3)]\n",
    "\n",
    "# no. of noisy samples for each example in test set\n",
    "num_samples = 30\n",
    "\n",
    "# dictionary noise(key)->test_stability(value)\n",
    "test_stabilities = {}\n",
    "\n",
    "# initialize dictionary\n",
    "for noise in noises:\n",
    "    test_stabilities[str(noise)] = []\n",
    "\n",
    "# compute stability on test set over noises\n",
    "for i in range(0,len(test_samples)): # calculate stability for each of 500 test examples\n",
    "    x = test_x[i]\n",
    "    x  = decodeExampleText(x, word_index, reverse_word_index)\n",
    "    stb = calculateStabilityLime(x, num_samples, noises) # returns a dictionary key(noise) -> val(avg.stability)\n",
    "    print(stb)\n",
    "    for noise in noises:\n",
    "        test_stabilities[str(noise)].append(stb[str(noise)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "lime_stabilities = open('lime-test-stabilities.pickle', 'wb')\n",
    "pickle.dump(test_stabilities, lime_stabilities)\n",
    "lime_stabilities.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    }
   ],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability of Shap explanations\n",
    "# stability = change in explanation / change in input\n",
    "# change in input = (noise/MAX_SEQ_LEN) ** 0.5\n",
    "# change in explanation = magnitude of difference between explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "background_data = train_x[:100] # background data for DeepExplainer\n",
    "test_samples = test_x[:500] # calculate stability over this set\n",
    "e = shap.DeepExplainer((input_seq, output), background_data, sess)\n",
    "shap_values = e.shap_values(test_samples[:])\n",
    "shap_values = shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "feature_names = [reverse_word_index[ind] for ind in test_samples[70]]\n",
    "shap.force_plot(e.expected_value, shap_values[70], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateStabilityShap(ind, num_samples, noises):\n",
    "    '''\n",
    "    ind: index of example in test set\n",
    "    num_samples: size of neighborhood around 'example'\n",
    "    noises: list of integers, each indicating the amount of noise\n",
    "    \n",
    "    returns: average stability, which is a dictionary.\n",
    "             maps noise to avg stability of 'example'.\n",
    "    \n",
    "    stability = vectorDifference(exp1,exp2) / normalised_noise ** 0.5\n",
    "    \n",
    "    change in input = normalised_noise ** 0.5\n",
    "    change in explanation = calculated using vectorDifference()\n",
    "    '''\n",
    "    assert num_samples > 0\n",
    "    \n",
    "    # get noisy_examples for example\n",
    "    noisy_examples = {}\n",
    "    for noise in noises:\n",
    "        noisy_examples[str(noise)] = noisifyExample(test_samples[ind], num_samples, noise) # returns a list of shape num_samples x MAX_SEQ_LEN\n",
    "        for i in range(num_samples):\n",
    "            # convert text to array of word-ids\n",
    "            noisy_examples[str(noise)][i] = noisy_examples[str(noise)][i].split(\" \")\n",
    "            noisy_examples[str(noise)][i] = [word_index[word] for word in noisy_examples[str(noise)][i]]\n",
    "            noisy_examples[str(noise)][i] = np.array(noisy_examples[str(noise)][i])\n",
    "        noisy_examples[str(noise)] = np.array(noisy_examples[str(noise)])\n",
    "    \n",
    "    # get shap values for example\n",
    "    shap_values_original = shap_values[ind]\n",
    "    \n",
    "    # get shap values for noisy_examples\n",
    "    shap_values_noisy = {}\n",
    "    for noise in noises:\n",
    "        shap_values_noisy[str(noise)] = []\n",
    "        \n",
    "    # calculate stability for each noisy explanation w.r.t explanation\n",
    "    stabilities = {}\n",
    "    \n",
    "    for noise in noises:\n",
    "        stabilities[str(noise)] = 0\n",
    "        shap_values_noisy[str(noise)] = e.shap_values(noisy_examples[str(noise)][:])\n",
    "        shap_values_noisy[str(noise)] = shap_values_noisy[str(noise)][0]\n",
    "        for i in range(num_samples):\n",
    "            vector_diff = vectorDifference(shap_values_original, shap_values_noisy[str(noise)][i])\n",
    "            stability = vector_diff / (noise / MAX_SEQ_LEN) ** 0.5\n",
    "            stabilities[str(noise)] += stability\n",
    "        stabilities[str(noise)] /= num_samples            \n",
    "    return stabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of noises\n",
    "noises = [x for x in range(3,21,3)]\n",
    "\n",
    "# no. of noisy samples for each example in test set\n",
    "num_samples = 30\n",
    "\n",
    "# dictionary noise(key)->test_stability(value)\n",
    "test_stabilities = {}\n",
    "\n",
    "# initialize dictionary\n",
    "for noise in noises:\n",
    "    test_stabilities[str(noise)] = []\n",
    "\n",
    "# compute stability on test set over noises\n",
    "for i in range(0,len(test_samples)): # calculate stability for each of 500 test examples\n",
    "    stb = calculateStabilityLime(i, num_samples, noises) # returns a dictionary key(noise) -> val(avg.stability)\n",
    "    print(stb)\n",
    "    for noise in noises:\n",
    "        test_stabilities[str(noise)].append(stb[str(noise)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "shap_stabilities = open('shap-test-stabilities.pickle', 'wb')\n",
    "pickle.dump(test_stabilities, shap_stabilities)\n",
    "shap_stabilities.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9a19b38cf54c1f81ee08cbd0ddb516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=70, continuous_update=False, description='Index of sample', layout=Layouâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def showExplanationLime(text):\n",
    "    exp = explainer.explain_instance(text, makePrediction, num_features=5, num_samples=2000)\n",
    "    exp.as_pyplot_figure()\n",
    "\n",
    "def showExplanationShap(text_sample):\n",
    "    shap.initjs()\n",
    "    feature_names = [reverse_word_index[ind] for ind in test_samples[text_sample]]\n",
    "    return shap.force_plot(e.expected_value, shap_values[text_sample], feature_names=feature_names)\n",
    "\n",
    "def showExplanation(text_sample, model):\n",
    "    '''\n",
    "    for a given text, outputs the prediction using makePrediction()\n",
    "    for the given model, displays an explanation using showExplanationLime() and showExplanationShap()\n",
    "    '''\n",
    "    \n",
    "    text = test_samples[text_sample]\n",
    "    text = list(text)\n",
    "    text = \" \".join([reverse_word_index[x] for x in text])\n",
    "    print(text)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    prediction = makePrediction([text]) # returns a numpy array of shape 1x2\n",
    "    print(\"Model's prediction -> Negative: {0:0.4f}, Positive: {1:0.4f}\".format(prediction[0][0], prediction[0][1]))\n",
    "    \n",
    "    if model == \"LIME\":\n",
    "        showExplanationLime(text)\n",
    "    else:\n",
    "        return showExplanationShap(text_sample)\n",
    "    \n",
    "    return\n",
    "style = {'description_width': 'initial'}\n",
    "layout = widgets.Layout(width='100%')\n",
    "text_sample_slider = widgets.IntSlider(value=70, min=0, max=len(test_samples), description=\"Index of sample\", continuous_update=False)\n",
    "text_sample_slider.layout = layout\n",
    "text_sample_slider.style = style\n",
    "i = interact(showExplanation, text_sample=text_sample_slider, model=[\"Shap\", \"LIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
